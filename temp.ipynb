{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.layers import Dense, Embedding, Input, Add, Dot, Reshape, Flatten\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.sequence import skipgrams\n",
    "from tensorflow.python.keras.models import Model, load_model\n",
    "\n",
    "import tarfile\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import nltk\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "import numpy as np\n",
    "from scipy.sparse import save_npz, load_npz\n",
    "from tensorflow.python.keras import backend as K\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.utils import plot_model\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists ...\n",
      "Extracting the file\n",
      "Found and verified datasets\\MovieSummaries.tar.gz\n"
     ]
    }
   ],
   "source": [
    "url = 'http://www.cs.cmu.edu/~ark/personas/data/'\n",
    "\n",
    "def maybe_download(filename, expected_bytes):\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  if not os.path.exists(\"datasets\"):\n",
    "    os.mkdir(\"datasets\")\n",
    "  if not os.path.exists(os.path.join(\"datasets\", filename)):\n",
    "    print('Downloading file...')\n",
    "    filename, _ = urlretrieve(url + filename, os.path.join(\"datasets\",filename))\n",
    "  else:\n",
    "    print('File exists ...')\n",
    "\n",
    "  print(\"Extracting the file\")\n",
    "  tar = tarfile.open(os.path.join(\"datasets\",filename), \"r:gz\")\n",
    "  tar.extractall(\"datasets\")\n",
    "  tar.close()\n",
    "    \n",
    "  statinfo = os.stat(os.path.join(\"datasets\",filename))\n",
    "  if statinfo.st_size == expected_bytes:\n",
    "    print('Found and verified %s' % os.path.join(\"datasets\",filename))\n",
    "  else:\n",
    "    print(statinfo.st_size)\n",
    "    raise Exception(\n",
    "      'Failed to verify ' + os.path.join(\"datasets\",filename) + '. Can you get to it with a browser?')\n",
    "  return filename\n",
    "\n",
    "filename = maybe_download('MovieSummaries.tar.gz', 48002242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in 10000 documents\n"
     ]
    }
   ],
   "source": [
    "def read_data(filename, n_lines):\n",
    "    \"\"\" Reading the zip file to extract text \"\"\"\n",
    "    docs = []\n",
    "    i = 0\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        for row in f:\n",
    "            file_string = nltk.word_tokenize(row)\n",
    "            # First token is the movie ID\n",
    "            docs.append(' '.join(file_string[1:]))\n",
    "            i += 1\n",
    "            if n_lines and i == n_lines:\n",
    "                break\n",
    "    return docs\n",
    "\n",
    "docs = read_data(os.path.join(\"datasets\", \"MovieSummaries\", 'plot_summaries.txt'), 10000)\n",
    "print(\"Read in {} documents\".format(len(docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_size = 3000\n",
    "tokenizer = Tokenizer(num_words=v_size, oov_token='UNK')\n",
    "tokenizer.fit_on_texts(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the co-occurence matrix\n",
    "\n",
    "Computes the co-occurence matrix and save it to the disk can either load the existing matrix or compute a new one by changing `generate_cooc` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cooc matrix of type lil_matrix was loaded from disk\n"
     ]
    }
   ],
   "source": [
    "generate_cooc = False\n",
    "def generate_cooc_matrix(text, tokenizer, window_size, n_vocab, use_weighting=True):\n",
    "    sequences = tokenizer.texts_to_sequences(text)\n",
    "    \n",
    "    cooc_mat = lil_matrix((n_vocab, n_vocab), dtype=np.float32)\n",
    "    for sequence in sequences:\n",
    "        for i, wi in zip(np.arange(window_size, len(sequence)-window_size), sequence[window_size:-window_size]):\n",
    "            context_window = sequence[i-window_size: i+window_size+1]\n",
    "            distances = np.abs(np.arange(-window_size, window_size+1))\n",
    "            distances[window_size] = 1.0\n",
    "            nom = np.ones(shape=(window_size*2 + 1,), dtype=np.float32)\n",
    "            nom[window_size] = 0.0\n",
    "\n",
    "            if use_weighting:\n",
    "                cooc_mat[wi, context_window] += nom/distances    # Update element\n",
    "            else:\n",
    "                cooc_mat[wi, context_window] += nom\n",
    "    \n",
    "    return cooc_mat    \n",
    "\n",
    "if generate_cooc:\n",
    "    cooc_mat = generate_cooc_matrix(docs, tokenizer, 4, v_size, True)\n",
    "    save_npz(os.path.join('datasets','cooc_mat.npz'), cooc_mat.tocsr())\n",
    "else:\n",
    "    cooc_mat = load_npz(os.path.join('datasets','cooc_mat.npz')).tolil()\n",
    "    print('Cooc matrix of type {} was loaded from disk'.format(type(cooc_mat).__name__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating the co-occurrence matrix\n",
    "Taking a specific word and plotting the frequencies of the most common 25 co-occurinng words. Making sure that the word distribution makes sense (Zif's law) and the co-occuring words are valid (visually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x180d56e77b8>,\n",
       "  <matplotlib.axis.XTick at 0x180d56e70f0>,\n",
       "  <matplotlib.axis.XTick at 0x180d56e1dd8>,\n",
       "  <matplotlib.axis.XTick at 0x180d5432898>,\n",
       "  <matplotlib.axis.XTick at 0x180d5432f28>,\n",
       "  <matplotlib.axis.XTick at 0x180d5438438>,\n",
       "  <matplotlib.axis.XTick at 0x180d5438940>,\n",
       "  <matplotlib.axis.XTick at 0x180d5438e48>,\n",
       "  <matplotlib.axis.XTick at 0x180d543f390>,\n",
       "  <matplotlib.axis.XTick at 0x180d543f898>,\n",
       "  <matplotlib.axis.XTick at 0x180d543fda0>,\n",
       "  <matplotlib.axis.XTick at 0x180d543f978>,\n",
       "  <matplotlib.axis.XTick at 0x180d5438518>,\n",
       "  <matplotlib.axis.XTick at 0x180d5443278>,\n",
       "  <matplotlib.axis.XTick at 0x180d5443780>,\n",
       "  <matplotlib.axis.XTick at 0x180d5443c88>,\n",
       "  <matplotlib.axis.XTick at 0x180d54481d0>,\n",
       "  <matplotlib.axis.XTick at 0x180d54486d8>,\n",
       "  <matplotlib.axis.XTick at 0x180d5448be0>,\n",
       "  <matplotlib.axis.XTick at 0x180d544d160>,\n",
       "  <matplotlib.axis.XTick at 0x180d54487b8>,\n",
       "  <matplotlib.axis.XTick at 0x180d5443828>,\n",
       "  <matplotlib.axis.XTick at 0x180d544d630>,\n",
       "  <matplotlib.axis.XTick at 0x180d544d9e8>,\n",
       "  <matplotlib.axis.XTick at 0x180d544def0>],\n",
       " <a list of 25 Text xticklabel objects>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6gAAAHtCAYAAAAUS1PeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xe4ZWdZN+Dfk4QWiBQTWogMQkRANEKkqQiCUoICCkgRQkcIioolYMNP0FhQUAGNtKCAoIBUEQwdpCQIghSNECEESUREEKQ+3x/vOnKIk8LM2Xu/mbnv68o15+yzZ94n++y91vq9bVV3BwAAADbtgE0XAAAAAImACgAAwCQEVAAAAKYgoAIAADAFARUAAIApCKgAAABMQUAFAABgCgIqAAAAUxBQAQAAmMJBmy4gSQ499NDetWvXpssAAABgBU499dR/7+7Dzu95UwTUXbt25ZRTTtl0GQAAAKxAVf3rBXmeKb4AAABMQUAFAABgCgIqAAAAUxBQAQAAmIKACgAAwBQEVAAAAKYgoAIAADAFARUAAIApCKgAAABMQUAFAABgCgIqAAAAUxBQAQAAmIKACgAAwBQEVAAAAKYgoAIAADAFARUAAIApCKgAAABMQUAFAABgCgIqAAAAUzho0wUAAADsi3Yd/9K1tHP6CcespZ11MIIKAADAFARUAAAApiCgAgAAMAUBFQAAgCkIqAAAAExBQAUAAGAKAioAAABTEFABAACYgoAKAADAFARUAAAApiCgAgAAMAUBFQAAgCkIqAAAAExBQAUAAGAKAioAAABTEFABAACYgoAKAADAFARUAAAApiCgAgAAMAUBFQAAgCkIqAAAAExBQAUAAGAKAioAAABTEFABAACYgoAKAADAFARUAAAApiCgAgAAMAUBFQAAgCkIqAAAAExBQAUAAGAKAioAAABTEFABAACYgoAKAADAFARUAAAApiCgAgAAMAUBFQAAgCkIqAAAAExBQAUAAGAKAioAAABTEFABAACYgoAKAADAFARUAAAApiCgAgAAMAUBFQAAgCkIqAAAAExBQAUAAGAKAioAAABTEFABAACYgoAKAADAFARUAAAApiCgAgAAMAUBFQAAgCkIqAAAAExBQAUAAGAKAioAAABTEFABAACYgoAKAADAFARUAAAApnDQ+T2hqo5I8owkV0zy5SQndvfjq+pySZ6TZFeS05Pcpbs/UVWV5PFJbpvkM0nu3d1vX035AAAAu7fr+JeupZ3TTzhmLe3sDy7ICOoXkzy8u6+V5EZJjquqayc5PsnJ3X1kkpOX75PkNkmOXP57YJIn7XjVAAAA7HPON6B290e3RkC7+1NJ3pvk8CS3T3LS8rSTktxh+fr2SZ7Rw5uTXKaqrrTjlQMAALBP+ZrWoFbVriTfnuQtSa7Q3R9NRohNcvnlaYcn+fC2v3bG8tg5/60HVtUpVXXK2Wef/bVXDgAAwD7lAgfUqrpUkucl+cnu/q/zeupuHuv/80D3id19dHcffdhhh13QMgAAANhHXaCAWlUXyQinz+zu5y8Pf2xr6u7y51nL42ckOWLbX79KkjN3plwAAAD2VecbUJddeZ+S5L3d/bvbfvSiJMcuXx+b5IXbHr9XDTdK8smtqcAAAABwbs73NjNJvjPJPZO8q6resTz2yCQnJHluVd0vyYeS3Hn52csybjFzWsZtZu6zoxUDAACwTzrfgNrdb8ju15UmyS128/xOctxe1gUAAMB+5mvaxRcAAABWRUAFAABgCgIqAAAAUxBQAQAAmIKACgAAwBQEVAAAAKYgoAIAADAFARUAAIApCKgAAABMQUAFAABgCgIqAAAAUxBQAQAAmIKACgAAwBQEVAAAAKYgoAIAADAFARUAAIApCKgAAABMQUAFAABgCgIqAAAAUxBQAQAAmIKACgAAwBQEVAAAAKYgoAIAADAFARUAAIApCKgAAABMQUAFAABgCgIqAAAAUxBQAQAAmIKACgAAwBQEVAAAAKYgoAIAADAFARUAAIApCKgAAABMQUAFAABgCgIqAAAAUxBQAQAAmIKACgAAwBQEVAAAAKYgoAIAADAFARUAAIApCKgAAABMQUAFAABgCgIqAAAAUxBQAQAAmIKACgAAwBQEVAAAAKYgoAIAADAFARUAAIApCKgAAABMQUAFAABgCgIqAAAAUxBQAQAAmIKACgAAwBQEVAAAAKYgoAIAADAFARUAAIApCKgAAABMQUAFAABgCgIqAAAAUxBQAQAAmIKACgAAwBQEVAAAAKYgoAIAADAFARUAAIApCKgAAABMQUAFAABgCgIqAAAAUxBQAQAAmIKACgAAwBQEVAAAAKYgoAIAADAFARUAAIApCKgAAABMQUAFAABgCgIqAAAAUxBQAQAAmIKACgAAwBQEVAAAAKYgoAIAADCF8w2oVfXUqjqrqt697bFHVdVHquody3+33fazR1TVaVX1/qq61aoKBwAAYN9yQUZQn57k1rt5/Pe6+6jlv5clSVVdO8ldk1xn+TtPrKoDd6pYAAAA9l3nG1C7+3VJ/uMC/nu3T/Ln3f257v5gktOS3GAv6gMAAGA/sTdrUB9aVf+wTAG+7PLY4Uk+vO05ZyyP/R9V9cCqOqWqTjn77LP3ogwAAAD2BXsaUJ+U5OpJjkry0SSPXR6v3Ty3d/cPdPeJ3X10dx992GGH7WEZAAAA7Cv2KKB298e6+0vd/eUkf5KvTOM9I8kR2556lSRn7l2JAAAA7A/2KKBW1ZW2fXvHJFs7/L4oyV2r6mJVdbUkRyZ5696VCAAAwP7goPN7QlU9O8nNkhxaVWck+ZUkN6uqozKm756e5EFJ0t3/WFXPTfKeJF9Mclx3f2k1pQMAALAvOd+A2t13283DTzmP5z8myWP2pigAAAD2P3uziy8AAADsGAEVAACAKQioAAAATEFABQAAYAoCKgAAAFMQUAEAAJiCgAoAAMAUBFQAAACmIKACAAAwBQEVAACAKQioAAAATEFABQAAYAoCKgAAAFMQUAEAAJiCgAoAAMAUBFQAAACmIKACAAAwBQEVAACAKQioAAAATEFABQAAYAoCKgAAAFMQUAEAAJiCgAoAAMAUBFQAAACmIKACAAAwBQEVAACAKQioAAAATEFABQAAYAoCKgAAAFMQUAEAAJiCgAoAAMAUBFQAAACmIKACAAAwBQEVAACAKQioAAAATEFABQAAYAoCKgAAAFMQUAEAAJiCgAoAAMAUBFQAAACmIKACAAAwBQEVAACAKQioAAAATEFABQAAYAoCKgAAAFMQUAEAAJiCgAoAAMAUBFQAAACmIKACAAAwBQEVAACAKQioAAAATEFABQAAYAoCKgAAAFMQUAEAAJiCgAoAAMAUBFQAAACmIKACAAAwBQEVAACAKQioAAAATEFABQAAYAoCKgAAAFMQUAEAAJiCgAoAAMAUBFQAAACmIKACAAAwBQEVAACAKQioAAAATEFABQAAYAoCKgAAAFMQUAEAAJiCgAoAAMAUBFQAAACmIKACAAAwBQEVAACAKRy06QIAAIB9z67jX7qWdk4/4Zi1tMN6GEEFAABgCgIqAAAAUxBQAQAAmIKACgAAwBTON6BW1VOr6qyqeve2xy5XVa+sqn9e/rzs8nhV1e9X1WlV9Q9Vdb1VFg8AAMC+44KMoD49ya3P8djxSU7u7iOTnLx8nyS3SXLk8t8DkzxpZ8oEAABgX3e+AbW7X5fkP87x8O2TnLR8fVKSO2x7/Bk9vDnJZarqSjtVLAAAAPuuPV2DeoXu/miSLH9efnn88CQf3va8M5bH/o+qemBVnVJVp5x99tl7WAYAAAD7ip3eJKl281jv7ondfWJ3H93dRx922GE7XAYAAAAXNnsaUD+2NXV3+fOs5fEzkhyx7XlXSXLmnpcHAADA/mJPA+qLkhy7fH1skhdue/xey26+N0ryya2pwAAAAHBeDjq/J1TVs5PcLMmhVXVGkl9JckKS51bV/ZJ8KMmdl6e/LMltk5yW5DNJ7rOCmgEAANgHnW9A7e67ncuPbrGb53aS4/a2KAAAYM/tOv6la2nn9BOOWUs77D92epMkAAAA2CMCKgAAAFMQUAEAAJiCgAoAAMAUBFQAAACmIKACAAAwBQEVAACAKQioAAAATEFABQAAYAoCKgAAAFMQUAEAAJiCgAoAAMAUBFQAAACmIKACAAAwBQEVAACAKQioAAAATEFABQAAYAoCKgAAAFMQUAEAAJiCgAoAAMAUBFQAAACmIKACAAAwBQEVAACAKQioAAAATEFABQAAYAoCKgAAAFMQUAEAAJiCgAoAAMAUBFQAAACmIKACAAAwBQEVAACAKQioAAAATEFABQAAYAoCKgAAAFMQUAEAAJiCgAoAAMAUBFQAAACmIKACAAAwBQEVAACAKQioAAAATEFABQAAYAoCKgAAAFMQUAEAAJiCgAoAAMAUBFQAAACmIKACAAAwBQEVAACAKQioAAAATEFABQAAYAoCKgAAAFMQUAEAAJiCgAoAAMAUBFQAAACmIKACAAAwBQEVAACAKQioAAAATEFABQAAYAoCKgAAAFMQUAEAAJiCgAoAAMAUBFQAAACmIKACAAAwBQEVAACAKQioAAAATEFABQAAYAoCKgAAAFMQUAEAAJiCgAoAAMAUBFQAAACmIKACAAAwBQEVAACAKQioAAAATEFABQAAYAoCKgAAAFMQUAEAAJjCQZsuAAAA9iW7jn/p2to6/YRj1tYWrIMRVAAAAKYgoAIAADAFARUAAIAp7NUa1Ko6PcmnknwpyRe7++iqulyS5yTZleT0JHfp7k/sXZkAAADs63ZiBPXm3X1Udx+9fH98kpO7+8gkJy/fAwAAwHlaxRTf2yc5afn6pCR3WEEbAAAA7GP2NqB2kldU1alV9cDlsSt090eTZPnz8rv7i1X1wKo6papOOfvss/eyDAAAAC7s9vY+qN/Z3WdW1eWTvLKq3ndB/2J3n5jkxCQ5+uijey/rAACAJOu7D6l7kMLO26sR1O4+c/nzrCQvSHKDJB+rqislyfLnWXtbJAAAAPu+PQ6oVXXJqjpk6+sk35/k3UlelOTY5WnHJnnh3hYJAADAvm9vpvheIckLqmrr33lWd7+8qt6W5LlVdb8kH0py570vEwAAgH3dHgfU7v5Akm/bzeMfT3KLvSkKAACA/c8qbjMDAAAAXzMBFQAAgCkIqAAAAExBQAUAAGAKAioAAABTEFABAACYgoAKAADAFARUAAAApiCgAgAAMAUBFQAAgCkIqAAAAExBQAUAAGAKAioAAABTEFABAACYgoAKAADAFARUAAAApiCgAgAAMAUBFQAAgCkIqAAAAExBQAUAAGAKB226AAAA9h27jn/pWto5/YRj1tIOsF5GUAEAAJiCgAoAAMAUBFQAAACmIKACAAAwBQEVAACAKQioAAAATEFABQAAYAoCKgAAAFMQUAEAAJiCgAoAAMAUDtp0AQAA+4Jdx790bW2dfsIxG63h3NoH2FtGUAEAAJiCgAoAAMAUBFQAAACmYA0qALBPsP4S4MLPCCoAAABTEFABAACYgoAKAADAFARUAAAApiCgAgAAMAUBFQAAgCkIqAAAAEzBfVABgL3mHqQA7AQjqAAAAExBQAUAAGAKAioAAABTsAYVAC7krP8EYF9hBBUAAIApCKgAAABMQUAFAABgCgIqAAAAU7BJEgAXajNsEDRDDQCwLxBQAdhjghkAsJMEVIALqXWFw0RABADWQ0AF2ENGDwEAdpaAClwoCYcAAPseARX4mgmHAACsgoDKhcoMwWjTNVh3CADAvkpAvRDZX4KRUAQAAPsnAfUCEs4AAABW64BNFwAAAACJgAoAAMAkBFQAAACmIKACAAAwBQEVAACAKQioAAAATEFABQAAYAoCKgAAAFMQUAEAAJiCgAoAAMAUBFQAAACmIKACAAAwBQEVAACAKQioAAAATEFABQAAYAoCKgAAAFMQUAEAAJiCgAoAAMAUVhZQq+rWVfX+qjqtqo5fVTsAAADsG1YSUKvqwCRPSHKbJNdOcrequvYq2gIAAGDfsKoR1BskOa27P9Ddn0/y50luv6K2AAAA2AdUd+/8P1p1pyS37u77L9/fM8kNu/uh257zwCQPXL69ZpL373ghm3dokn/fz2vYdPtqmKeGTbevhjnaV8M8NWy6fTXMU8Om21fDHO2rYZ4aNt3+qly1uw87vycdtKLGazePfVUS7u4Tk5y4ovanUFWndPfR+3MNm25fDfPUsOn21TBH+2qYp4ZNt6+GeWrYdPtqmKN9NcxTw6bb37RVTfE9I8kR276/SpIzV9QWAAAA+4BVBdS3JTmyqq5WVRdNctckL1pRWwAAAOwDVjLFt7u/WFUPTfI3SQ5M8tTu/sdVtDW5GaYwb7qGTbefqGHLpmvYdPuJGmZoP1HDlk3XsOn2EzVs2XQNm24/UcMM7Sdq2LLpGjbd/katZJMkAAAA+FqtaoovAAAAfE0EVAAAAKYgoK5BVe3utjurbvPAdbcJ7N4mjgEAs6uqQzZdA/PYOldWlXyyn/MGWJGtgFhV1Wte6FtVd0rymHW2yQWz7oPutoP9VAFpfzv5bB0DqurYqrrUpn8f+9vrv922z8RFqupim65nyyZ/JxvqRJ3qmMTGPK2qrrfc8WG/53ORQ5Kku79cVQds6vWoqotV1e9X1UGb/p1suv1N2W8vUlZpOdBeavn22VV1lTWXcIMkL91WyzSq6vCqOqqqbrLidv6oqm63yjYuqKo6pKq+OxkH3XW2va1z5Cer6q5LPRsbXa+qA6vq4K3XYZ0X5edsq6oOXme7VfU9SX6ouz+97k6rbbUcunx5h6o6chM1bKtlqxPv0PN77or8fJK7bKjt/7X1e9i6IFtju//b1ibej9s6bW5TVZecZeRkf7oY3PaaX2JD7V8vyWW6++1JHrGJ0dRNvwbnqOWg7u4NhrJrVtW3bTiU/W5VnVFVN+juLy+vxyaOCd+Y5Drd/cUkGz0mbOp6YdME1NW4bpJfrKqnJzm0u8/Y+sGqP/RLKPupJDdNku7+fA0b/11X1WFJ/jLJbZL8aVUdtYI2tl7ftyU5rqoetdNtXMA6ti6+fyrJbyZ5bFX9+QZHKs5M8u1J0t1fWnP7W6/FTZP8cZIXVdUvLbWsJbBX1QFLALhYVf1GVZ2U8Rm996o7cbb9P94syT+co661vR+q6kpJbllVv5Dkd5J8cHl8I8eG7v5SVR2U5C+q6grraHN5H/QSiq+f5JnL4+v8PWx9Hu5ZVX+W5E+q6i1VdcN1dmBt6yT6iap6SFV9z/IeWbltr8HtkvxYki8tv5eD1t2JV1XXXS7Kr5es72JwWzC6ZlVduaouv452t7V/4PKaf2tGB+Ymptp+PMkBVfXeJId196eW2tbyeZzhNdjWgXlskqcv56Y7VdWVl8fX9VrcI8mvJ/mzJC/M6MRcSyfudt19/ySPT/KqqnpKVV1uEx3aST6c5KJVde3l2mFdv4et98OVq+p2VfWrVfWd62h7NhsPLfui7j41yd8nuV2Sz1bV0VX19cuPr7LiEYNXJDkuyY9W1fOr6lt6WOtJ/1z8TpKnJHl3kg909zuq6uo7HFQvVlWX7u6nJLlbkj/cwX/7Alsuvi+T5B5JfiXJ+5K8aTkZ3midB/7lgus1Sa5aVa+oqiOS9Z34tgXi/5fkXUkeleQ7quqdy0lxLWUsfz4+yWUy7tH8nozQvvKR9qq6dpIjk9yuqu67dfGx5p7Rz2Tc+/qnk5yW5IZVddi2k//h6ypkuSDM0jv9/iTftI6Lj23HwXsnOSzjOHnwOn8Py7Hh4hkdiU9LckySk5I8q6p+aB01VNU3LH/eJ+M4eeMkP5rk2Kq6aVVdepXtbzsmPCrJLybpGvdOf09VPWSVbSdfdRH4sIx7Df5GkvtX1S8vHakrb385FxyV5C+SPC/JT1fVD20dG1Zt2+/gt5N8rLs/VVXXWi6Kj1hTDf+a5BEZ16K3qqoHVNXF1vV5nOQ1+PLSOfLLGeen9yX53oyOm3WeI45b2nxhkosneWSSP6+qG62p/e0z/t6XcWw8KskHq+pXk7V2aB/Z3Z9O8qqM42K2RnJrjC7frqoudd7/yp7Z9v/4+CTflvEa3HOpa5olKetw0KYL2NdUjTWn3f2sqjozyTWTPDbJW6vqGRkno19N8uxVtN/dn09yYlX9RcYB55lV9dYkP7bukbPtquoiSc5K8qyM1+Cxy49+OMnFkrxjh5q6dpK/raoTuvu3dujf3FPfnuQ5Sa6c5Bu7+17L4z+XcWH2D+fy9/ba1vuwqq6Z5DPd/eGqumeS+yS5UZIPr+PEV18Zubxxxv/v7y/tvmG5GH/8ckHy1FXWsbwWl0py1SR37O7/WS7CL55xUf6a7v6PnWxz63ewtP+eqnpQkrtmnHCOqKq/T/K33f2ZnWz3XGo5sLs/uRwXOskVl1rOrKqXZISUM7OGDp3lovyRVXVKxnHwDUmuvLxPrp7k6CT/090vXEHbW7+TdyXZleT7knyuqt6W5INrvBg8OskZ3X3y8hl5YlV9PMl1kjx/lQ3XmFL8tKp6aZJvTXK77v54Vd0sY3bLvZO8LsnTV9T+Jbr7s0tI/veM38N9M0LKzya5W1U9q7v/cxXtJ/8bCi6V5PuT/ECSAzM6kI5NcvMkz11V21vtL1/+WEYH5puWtm+d5NpV9ZaMY8OOvx+3H5eW3/khGdcJd8w4N30gyRUyOpPX4ZJJfi/Jf2VcG92tqn63u1+yqgZneQ221XGzJE/v7rcleVtVfXOSk5bz0qtWWcNSxy2SvDnJRTOOB0ctx+nnJVlpZ9V2y4y/b8p4P1x/OWddM8kLl46rO3X3a1dZQ1VdI8mrq+pZGcfBW1XVLTOOE4dnXM99XcZMyVXVcIskl+zuxyznpl9efnTXqnpVd394VW3PxAjqDtrWK3q55UN1dnf/cZI7Z7zWP5Pkld29knC6XXd/orsfneTuSd69yXC61POFJKdnTCu8aHe/vKoul9E79bwdbOftSa6U5OBVjwLszjlGgV6f5LuS/FXGqFWq6scyDjwrC6fJV/W63jrJ66rq1zJOtg9O8kdV9ROrbH9bHVvr6n46Iwzcd6vnsbufn+Rqqw6n22r5dMa0nadV1ZW7+5Pd/eQkh2accHbaQUlSVbetqkdmXPg8P8kTknwxyQ9lnPBWbtvn/4lJPt/dj82YyvV1SR661PKX66glyb9lBICvzwgkt0jyhBpLIv48yXcn2dHOgi3L8fmSGeHwoUlelhHKHppxIbKuqb6nZowa3n9bWLlEku9YQ9sfz5jKd4mMac7HJUl3vybJLyR5bcbsgh1XVd+R8ftNd38oyZMzlkD8W3c/LMk/J/nmVYbTbY5NckTG9OKPdfcbMvZuuFdVXXYVDW5/fy0jUzdJ8k9L+7+V0SlweMZ011V1llx129fvSPJ3Sf46YybJcUn+NCMkXmRF7W+f4n33JD+R5P5Jrp7kD5K8MslTq+rBq2o/I2RseUfGuXrdr8FFl+PR9ZZ6blpVN6kxo+N9Sd6SMcCxct19csZn/6pJPlJj6cXBSV7X3X+zjhq2OTjJKd39yaW29yd5WEZY/PSqG+/u0zI6ri6d5EkZ74fjknwoyeMyjhvfuuLOzI8keWVVPSLJa7r7nUuH3sMyOnL2C7XGmU37jaXn5QtJviHjRP+i7v6b5UNfS1jbb9SYzve57n5/Vf1kktsn+VKSs5N8qLt/fqMF7qBlpOpLy8n17IwLzrtnvA/ekOQOSe7d3e9aYQ0HdfcXq+q2GSe4KyS5SEY4+f6MQLYryQnd/c+rquOcNWWMlj8448T7p0lO6+7/WXG7B3f3Z6rq+zL+v1+R5PiMTcw+lTF6f6XuXslmOcvFx7OTPDrjd/8tSf5fdz+zqr6zu9+4inbPpZZLZLwXb5/kP5OckDGV6rJJDl5Hr+y2z8cBGRdlt8gYsdqV5OVJfnNFo0Zb7T48Y6TsO5K8q7vvXWNq84OSnLqKUdvzqOkGSZ6REcZfmrFh04O6+81raPvwjGPD1TI6UP8tyVO6+/Urbvd7krw3I5hdJslfbYXRZfraGzOOSyvtLFkC0jEZF+VfTPJ73f2XVXX7JPfv7h9YUbu7uvv05esbZyx7OCzJ47r76dvrW1WnclXdK2Na/Se6+5+WY9RVk7y+u/+9qp6d5O+6+/dX0f45anlLkvssM0xumuR+GeHkD5YA9/kVtXvPjDsdPGI5Ft8m4xz5uu7+z1W/Bsv772cz3nt3TPLjGfuGHJGvdM79SJKbrqmzZntdj804Rl4jycO6++Xran+p4eIZM88+lfHe+EKNvUTO6u4nrrjteyT5Ync/Z/n+5hnXLN+Q5MeXEe5Vtr818+3rMvZHuHWS23b3K6vqOUne2d2/vsoaZiKg7pBtb6zbJvmJ7r51Vf1LxkjBjZL8Y5IndvdKeqZntfQYvz3Jg7v7zVV1xYwTwdEZPZf/2nOsj91rVXWZ5eR2h4w1Ta/N6HU7OGPq3suTvKK7P7jCGg7r7rOXUco3Jzk5Y9T6Jkne3N2/u/QKPyLjZPjgHusAd7qOram9V87YVfpaGSN0/50xkvhdSX6nu/98p9veVsPBSX4yozPkdkke1WNK5bdlXJDdOskpSf6yu3esV7LGhj/37e7fqKo/SvK+7n7c8rPvzRJWu/usnWrzPGr5qttcLb/7q2RcFN0xo1f6cd199qprOUddT8tYe/jxjGn5N86YEn9Wkl9ZRSdejTXhf5sxYvrYJG/v7sdV1XW6+x93ur1t7R6QMXjby3TC22Z0YJ7c3a+qqrtkjLaf3t1vWmEdB2ZMU3t9xlTKl3f3S6rqOklulTHN8CMZF6UrCQbbanlQxjHptIzj1PsyLtbv1N1/sMq2z1HHlTLW+90346L87RmdBB/b6ujb4fbuleSfMi62P7A8dvckP5jxnnh2d7/snJ/bVaiqF2eM1t6nu9+5PPaDGf//x6yy7aWtr0/yJ0me1N2vXB67QsYo8r27+2Mrbv+yGefph3f3fy+PHZjRifuQVXVSbGv/GhkzOL4uo9PwbRnH5MMzpo+etIzqr9Uys+3qSQ7p9Uwv3j7d+sCMKd+fyxhNv22v8RdNAAAPWklEQVTGMfu6GUFt1e+Je2Qsv3pPkuO7+73L4w/O6Dz5tyQ/3N2f2+F2tzpQD0pyqeU68nIZS2/uv7R7Vncfu5Ptzk5A3WE1did9ZUYP/bW6+yFVdWKSSvKTWwfC/cXyelymux9eVbfKWAP55Yxg9MnNVrdzqmpXkldnjFJeKcmJ3f2+5YL0+hmjBZ/JGB1YyYdu6Qx4VcY0uQ8m+a/ufsJyYX6tjLD2y8tI9s9lvD/vs4pattX0FxkdETfKmMb3gOXxG2dMgT9txe0fnnGCu3KSu3X3y7b97AqrOOFV1R9nnOCeluTXMqbkPCr53w1y/jTJi7t7pevczlHTPTPWtH10+f6QjNus3DLJz3X369ZQw1anxYMyAvpttv3s0IxOqy/0mG62ivZvvrTxiiRP6O7vWh5/UZJf7BVNu6+qy291RlTV32V0CnwkYzT9f5L8WXe/dRVtn6OOi2aMyvx2xjH48G0XhhfP+Iwe0t0vXlH7WzM77pux9vRaSb4pyWczRvTemuStKzw+br3/bpoRCL4lY5TifUk+kbHc5JoZ6w8ft8oOpCUcXjUjiL196bi9b5IjunuVU1vPWcdRGR2HpyZ5YI81f1fs7n9bU/v3yeggeH7G6Pk1M/Yp+PZ1tL+tjgP6K5vFXSXJl7v7zDW0+5CM9c93y3jfPTTjc/FD3f2zq25/Bts+lw/L6DT+t4zP5JMywuolMq5l/n3VNSxfXzxjzeePZJwrfrrHmvnLJ7nZKs/bVfXbGSPp/5Rx3fK2jOu5r+vuj6+q3VlZg7pDlnCQjE1GTskYNXvv8tiXkrxxPwynB2TM4/9MVf1ORu/91qji9TdZ205bpm3dL2PTkbtl9IRuret6csamLK9eZa/48m8/IGNqzP0yprClu/+zu/8uo4f+DsvTfztjWuPK1LaF/hmb8vzh8vi9k7x3DeG0uvsjGaPFP5Xk12rsYnytZUrXKjbhuUjGZkNXS/KSjPVd188YNb1eVf1IRm/wytf1bDsmJWP976uq6n5LUPhUxonvOesIp8lXrUf+wYwRvK2gnIzjxFt3OpzWBVsTfrFVhdPFY6rqEzXWff91jyUNJ2WMHv1Lkl9awvPKLCNTX+7uP814Hf4xyVvqKzvmfi7J92RF78tldskXl9klP58xMnJwxr4En82Y6n3Eio+PWzN1nprxGrwwY9T+PhmB+bcyRm0Oy5jeuDLL6Nw9kzy3xpKgz/aYurfWUNLd78gYOX5BkrOr6k7rCqeLZ2ZcE3x3Rsf+T2fMsFmr7bO4uvuMdYTTpa0nLjMGfjBjNsHfZ3RsrnzkcgbbwuklMq5N/jBjE82DMzr775zkP1cZTheHLPUc0d3/092PzOiwu0jGcfLu3X3WKsJpVf1wjXtBXzXJDZPcKaOz5gYZx4g7ZD/NakZQ99I5huYPyegR/3zG9tCvzhg9ukR332CDZW7MMo3lARknwfssPbRvzpg+8ZqNFrcCNdZR3TPjRPu+jGmlK90Q6VzquGnGBdeBGQf9N2fsjPewXtadrnoaWY2dCG+TsVPu5br7Z2ss9H9hRk/kykbQt/7fauwK+5ltI4c/k3FB+q9Jntxjo6adbvsiGVMFvyHjZPNPGRukXTmjd/gNvYaN0rYdm+6UEUDun9E7+6aMY9NPZUybeueqazlHXY/OOCY+fNtjb8yyDnCH29r4mvCljgcm+d0kH8sYyX/r8vgVM3b4XtnU3qWdX8/YBOZdyei0WqZzPizj8/n5jCm/v7mCtndl97NLvidjRPuyGbNLHrvTU+e21bB1IXzzjNk7d1kev3SSP8rYSPAxS6fOZbr7E6uoYzd1VcZu2icluWcva982YTl3HbKGMLC7ti+dsS/Al7eO1fujGtOOr9ErXus4m2Wm3UW6+5eX76+WcQ39AxlL405dcft/lXFueE/G8fCUjBkWL87Ys+KKSe7eO7wkaelAfVDGYMJ/Z9x+8RHLz66REdCvlTENfa3LcGYgoO6QbUPz78vo/Xpxxkn/+hkbAa1s3eGMquroJA9M8ms9bnGydYHwK0mu29132nCJK1Vj/cBDMg4wp2S8Fl9eZSDcTQ0HZkxbe3TGReBDuvsZ26ezrKjdjS703/Zeu17GJjSfzuiRfHWPNXeXyAjMH1lhDffMCIUPzwhGv5CxW+dnV9XmOdrfvh76VzPCyYcy1v1dKmOk7AO9/h0at068j80YOXtxxsn/Vt39/TvczgxrwrcC8o0zpnBeOmM99LMzplSubXf15X3//ozpnI/u7lOXgPSjGbf52fFwuq3t783oGLplxhTO31gev3RGJ9a/rOqi/BydyL+QcZ5+akYg/3iNW0jct7vvvor2L2CNGwuHsElLSHtmxpTaR2wdh5bPxJVXfe1c47Y2P5+xJ8dfZ9yG7e8yZlJcJmPm2TWWmWA73fbFuvtzVXVcxnH4mzI6zB7by23vquobe1mvvr8RUPdCVf1wRs/vezJ2Jb1HxtSlozLWnZ2S5GX729Te5H+nlD0xY0OWZ2dMZ6uMqSwn94oXu8+ixgYkt+zux2+whstlHPz/ZJlmt5KR05psoX+NDYr+Jl+5x+A3JTkjyWuSvHZdnQXL1M6HZnRe/UjGPT5XOXK9K18ZsfqGjJHid1bVYRlTfa+b5Jd6BZtjnU9d11u+/GDGjso3yei4eUHGcXLHNpA7j1G7m2V9a8K3r2v6+oz3wLsy1qD+ZkZgu3N379htts6rjho7Wd8l4wLslhlrnH6x17BZ11LHRmaX1Li35bdnfP5fnbHW704ZUyovnvFa/F53/1WtcPdc4P+qqiMyjsXXz1h3+umM/Vpevab2fybj/q8Xzwip/5LRkfe3q5xJUWMjy4dmzLq8c8ZOzgdkXCtdMclLetwGb78loO4hQ/Pnrqou3svtQ5appr+acauTX8i4EF3JNC7O36pHT5c2NrLQf3vwrnGPwRMzplP+4/LYTTIukF/f3c9aVR3nUtvBGVP4/nhN7W2NWN0qyR9tTZ1afnZqkp/q9WyMtNVpcYeMMHqJjOPlC5O8YJUjRuczanerjJkt67ily09k3EbmEhkXYB9Y6rphVrxR2LmE5PdmrPf7xYy16g9ex5TzbTWtdXZJjfvePjNjnesv9di5+eYZ68S/O+NC9JmraBv4v7adF3404zhwZMao5Z9mdFw+Oslx3f2kFddxUEan3TdnzHj8fEZIvWTGPdPfluRNW6OZK2j/GhkzeS6Z5C7d/fplpsstM5ZoPbRXtGnghYGAuocMze/e8oH/ySTvzphS+bnl8Rcl+fru/s5N1sdqnMtsgmMyRuv+K2NN5mtW2VlTE9xjcCbbRqx+PuP38ocZG7Y9vNdwG4lz1PL6jLWf9864ncmnMnqsn5LkeavqNNnUqN229q+RMW3sCxn3XTwg48LjTRnTSteyk/m2kHzxjPPUBzPC6XUz7oe59iUo65xdUlXfndEhcOMkX5/kkRnr8k/KGK35+KpmlgC7V1VvythR+2EZm7RdLOM+6c/NuB/uupbEHJ4x+3FXxn1oP5bkGzOOjw9ecUfq1k7Od03y0STHZeSJX9rpZS8XNgLqHjA0f+6q6poZvePJco+77n5bVT0uY8TktZurjlWYZTZBTXSPwZksG288PGOjpg9lTCtd28ZIVXXDJD+csXP0yd39rVV1rYyp/z/X3a9YQw0bWxNe497Yv5jx3nxKxoXQbZPcuLs/s4b2zy0kvzHJ/bv7P1ddwyyWDtS7Z+wUe0CSF3X38fvbMQE2rcYu/8dk7Efw0u4+alkG8sKMjetWOnJYVYf02M1++2PflnG9cK2Mc8ShW53eq1bjVmvHZXTifirj3PjydbQ9KwF1DxmaP29VdeuMKVWHZqyD6+6+5WarYhVmm01Qk9xjcDbLiNUNu/upa2jrhhlTpV7R3f+1THG+asbFyA9k3O/wMd19x1XXco661jlqt7VL7d9m3Pf0vkle191vrqpLrnNvgk2H5Nksm0MdneTUZX2ugAprtlwzf3vG8q/bZ9xa5QG9+vuz78pYj/6k7v6t3fz8KRn3Kv+rVdaxO0uH8pG9hntjz05A3QuG5r9aVT08o+fpChkXQx/I2Kr7kklOW1dPFOsz62yCpSf0eUnemjFF55NVdanu/vS6a9kfVdU9kvxExo6xT0/yDxm7Gv9eRsfVlzN2kv2LTdW4SksAul3GNLG7Zmz88emMDfTu3N2nrKmOaUIywDnVuNvAYzPWoV4j41Z4Kx85XPYoeGjGdcpvbQ+jVfWXGfulrLwzl3MnoO4AQ/P/20P/qxnB5Jjlzxck+Rk90/u2WWcTLCFhinsM7o+q6pCMtZ83yVj/+NKMtT27Mu41+YbNVbdeVXX7jAuw78uYWbCOac1ThGSA87Iswbh6xq2WXrXGdg/KODb+WMZeGVtB+a7dfbN11cHuCag7aH8emq+qp2dMl/qD5fsrZEzzfPj+tlHU/mjm2QTlHoNrVVUX6e4vLBtnJWNk/ZoZt1h5eUbP9H6z7nG7rddmQ22vPSQDzK7GPdsfnOSHMtbAvmodO7xz3gRUdkRVHZPkRklOSPLZZV3Pi5P8mZGr/YfZBPu3qrpMj/vf3iHJozIC6ZkZx4bKGM17SnefuLkq92+bDMkAs9pfdvi/sBBQ2SvL5ic3TXKbJDdP8trlv29LcovuvskGy2ND9ufZBPurbRtPPDFjY7Qnd/c7l06L78+419yjM3bP/eKm6gQA5nbQpgvgQu/JSS6dcUPjLyS5V8a99l6R5GUbrIsN6u5PZGxQxH6iu0+vqvsluU+SWyX5RJJ3LlOrn1VVf5/kb7r7jZusEwCYm4DKHls2wvlQkl/o7i9V1Qsybv5+h4zRk7dstEBgrbr7VVX1xiT3TPLzy27Kf5jkS0nOFE4BgPNjii97rKrumuTWGaOlL1nud7i1c+pbu/tfNlogsDHLNO+HJ/mZjI6sO3f3OzdbFQAwOwGVPbLs0PnIJGcl+fckJyd5c8b9Tq0vA5IkVXWdJDd0TzkA4IIQUNkjVfW4JE/o7n+uqh9N8r1JPpuxxuxFm60OAAC4MDpg0wVw4VNVt0vy40numCTd/WdJjk9ydpLPbbA0AADgQswIKl+zqrpoxk6dP57kn5M8ytoyAABgbwmo7LGqulyShyS5c5JTkzwg4x6H3lQAAMDXTEBlry2boNyyux+/6VoAAIALLwEVAACAKdgkCQAAgCkIqAAAAExBQAUAAGAKAioAAABTEFABAACYgoAKAADAFARUAAAApvD/ATO9PlhAgLDiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "word = 'cat'\n",
    "assert word in tokenizer.word_index, 'Word {} is not in the tokenizer'.format(word)\n",
    "assert tokenizer.word_index[word] <= v_size, 'The word {} is an out of vocabuary word. Please try something else'.format(word)\n",
    "\n",
    "rev_word_index = dict(zip(tokenizer.word_index.values(), tokenizer.word_index.keys()))\n",
    "\n",
    "cooc_vec = np.array(cooc_mat.getrow(tokenizer.word_index[word]).todense()).ravel()\n",
    "max_ind = np.argsort(cooc_vec)[-25:]\n",
    "#print(max_ind)\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.bar(np.arange(0, 25), cooc_vec[max_ind])\n",
    "plt.xticks(ticks=np.arange(0, 25), labels=[rev_word_index[i] for i in max_ind], rotation=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining GloVe model with Keras\n",
    "\n",
    "In order to define the GloVe model, a custom loss function is required. However, GloVe loss essentially boils down to a mean square error, which makes it easier to define as a custom loss function. Let's have a quick look. GloVe loss is defined as,\n",
    "\n",
    "$J = \\sum_{i,j=1}^{V} f(X_{ij})(w_i^T\\tilde{w}_j + b_i + \\tilde{b}_j - log(X_{ij}))^2$\n",
    "\n",
    "where $X_{ij}$ is the $i,j$ cell of the co-occurence matrix and $w,\\tilde{w},b,\\tilde{b}$ are weights and biases. For a full explanation refer the [original paper](https://nlp.stanford.edu/pubs/glove.pdf). When you play around with parenthesis you will start seeing the squared loss.\n",
    "\n",
    "$J = \\sum_{i,j=1}^{V} f(X_{ij})\\{(w_i^T\\tilde{w}_j + b_i + \\tilde{b}_j) - log(X_{ij})\\}^2$, \n",
    "\n",
    "which is like,\n",
    "\n",
    "$J = \\sum A ( B - C)^2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_glove_model(v_size):\n",
    "    \n",
    "    w_i = Input(shape=(1,))\n",
    "    w_j = Input(shape=(1,))\n",
    "\n",
    "    emb_i = Flatten()(Embedding(v_size, 96, input_length=1)(w_i))\n",
    "    emb_j = Flatten()(Embedding(v_size, 96, input_length=1)(w_j))\n",
    "\n",
    "    ij_dot = Dot(axes=-1)([emb_i,emb_j])\n",
    "    \n",
    "    b_i = Flatten()(\n",
    "        Embedding(v_size, 1, input_length=1)(w_i)\n",
    "    )\n",
    "    b_j = Flatten()(\n",
    "        Embedding(v_size, 1, input_length=1)(w_j)\n",
    "    )\n",
    "\n",
    "    pred = Add()([ij_dot, b_i, b_j])\n",
    "\n",
    "    def glove_loss(y_true, y_pred):\n",
    "        return K.sum(\n",
    "            K.pow((y_true-1)/100.0, 0.75)*K.square(y_pred - K.log(y_true))\n",
    "        )\n",
    "\n",
    "    model = Model(inputs=[w_i, w_j],outputs=pred)\n",
    "    model.compile(loss=glove_loss, optimizer =Adam(lr=0.0001))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clearning session and analysing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 96)        288000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 96)        288000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 96)           0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 96)           0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 1)         3000        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 1)         3000        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1)            0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 1)            0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 1)            0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1)            0           dot[0][0]                        \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 582,000\n",
      "Trainable params: 582,000\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = create_glove_model(v_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run and eval Glove¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\tekbac.deeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch 0: 3080.0761646789542\n",
      "Loss in epoch 1: 0.7902729443804617\n",
      "Loss in epoch 2: 0.3762087574241899\n",
      "Loss in epoch 3: 0.26511143066882104\n",
      "Loss in epoch 4: 0.2176792402315259\n",
      "Loss in epoch 5: 0.192896554466248\n",
      "Loss in epoch 6: 0.17878403617505492\n",
      "Loss in epoch 7: 0.1682449689781125\n",
      "Loss in epoch 8: 0.1619124566234104\n",
      "Loss in epoch 9: 0.1563303735583753\n"
     ]
    }
   ],
   "source": [
    "cooc_mat = load_npz(os.path.join('datasets','cooc_mat.npz'))\n",
    "batch_size =128\n",
    "copy_docs = list(docs)\n",
    "index2word = dict(zip(tokenizer.word_index.values(), tokenizer.word_index.keys()))\n",
    "\"\"\" Each epoch \"\"\"\n",
    "for ep in range(10):\n",
    "    \n",
    "    #valid_words = get_valid_words(docs, 20, tokenizer)\n",
    "    \n",
    "    random.shuffle(copy_docs)\n",
    "    losses = []\n",
    "    \"\"\" Each document (i.e. movie plot) \"\"\"\n",
    "    for doc in copy_docs:\n",
    "        \n",
    "        seq = tokenizer.texts_to_sequences([doc])[0]\n",
    "\n",
    "        \"\"\" Getting skip-gram data \"\"\"\n",
    "        # Negative samples are automatically sampled by tf loss function\n",
    "        wpairs, labels = skipgrams(\n",
    "            sequence=seq, vocabulary_size=v_size, negative_samples=0.0, shuffle=True\n",
    "        )\n",
    "        \n",
    "        if len(wpairs)==0:\n",
    "            continue\n",
    "\n",
    "        sg_in, sg_out = zip(*wpairs)\n",
    "        sg_in, sg_out = np.array(sg_in).reshape(-1,1), np.array(sg_out).reshape(-1,1)\n",
    "        x_ij = np.array(cooc_mat[sg_in[:,0], sg_out[:,0]]).reshape(-1,1) + 1\n",
    "        \n",
    "        assert np.all(np.array(labels)==1)\n",
    "        assert x_ij.shape[0] == sg_in.shape[0], 'X_ij {} shape does not sg_in {}'.format(x_ij.shape, sg_in.shape)\n",
    "        \"\"\" For each batch in the dataset \"\"\"\n",
    "        model.fit([sg_in, sg_out], x_ij, batch_size = batch_size, epochs=1, verbose=0)\n",
    "        l = model.evaluate([sg_in, sg_out], x_ij, batch_size=batch_size, verbose=0)\n",
    "        losses.append(l)\n",
    "    print('Loss in epoch {}: {}'.format(ep, np.mean(losses)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model and the embeddings to the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings(model,save_dir, tok, v_size):\n",
    "    \"\"\" Saving data to disk \"\"\"\n",
    "    \n",
    "    # We need to add the 0th index to word list manually\n",
    "    word_list = [\"RESERVED\"]+[tok.index_word[w_i] for w_i in range(1,v_size)]\n",
    "    emb_w_df = None\n",
    "    for layer in model.layers:\n",
    "        if 'embedding' == layer.name or 'embedding_1' == layer.name:\n",
    "            if emb_w_df is None:\n",
    "                emb_w_df = pd.DataFrame(layer.get_weights()[0])\n",
    "            else:\n",
    "                emb_w_df += layer.get_weights()[0]\n",
    "    \n",
    "    emb_w_df.insert(0, \"word\", word_list)\n",
    "            \n",
    "    emb_w_df.to_csv(\n",
    "        os.path.join(save_dir, 'embeddings_w.csv'), index=False, header=None\n",
    "    )\n",
    "    \n",
    "save_embeddings(model, 'datasets', tokenizer, v_size)\n",
    "model.save('glove_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing out some similar words of a set of valid words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_words(docs, size, tok):\n",
    "    \"\"\" Get a random set of words to check the embeddings \"\"\"\n",
    "    np.random.seed(100)\n",
    "    valid_docs = np.random.choice(docs, size=size//2)\n",
    "    valid_words = []\n",
    "    for doc in valid_docs:\n",
    "        np.random.seed(100)\n",
    "        words = np.random.choice(tok.texts_to_sequences([doc])[0],size=2)\n",
    "        valid_words.extend(words)\n",
    "        \n",
    "    return valid_words\n",
    "        \n",
    "\n",
    "valid_words = get_valid_words(docs, 100, tokenizer)\n",
    "def load_embeddings(filename):\n",
    "    print('Loading the word embeddings from the disk')\n",
    "    embed_df = pd.read_csv(filename, index_col=False, header=None)\n",
    "    embed_df = embed_df.set_index(0)\n",
    "    print('Embedding shape: {}'.format(embed_df.shape))\n",
    "    embed_mat = embed_df.values\n",
    "    words = embed_df.index.values\n",
    "    return embed_mat, words\n",
    "\n",
    "def get_cosine_sim(emb, valid_words, top_k):\n",
    "    norm = np.sqrt(np.sum(emb**2,axis=1,keepdims=True))\n",
    "    norm_emb = emb/norm\n",
    "    in_emb = norm_emb[valid_words,:]\n",
    "    similarity = np.dot(in_emb, np.transpose(norm_emb))\n",
    "    sorted_ind = np.argsort(-similarity, axis=1)[:,1:top_k+1]\n",
    "    return sorted_ind, valid_words\n",
    "\n",
    "embed_mat, words = load_embeddings(os.path.join('datasets','embeddings_w.csv'))\n",
    "best_ids, wids = get_cosine_sim(embed_mat, valid_words, 5)\n",
    "pd.Series(words).to_csv(os.path.join('datasets','index2word.csv'))\n",
    "for w, bi in zip(wids, best_ids):\n",
    "    print(\"{}: {}\".format(words[w], ', '.join(words[bii] for bii in bi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
